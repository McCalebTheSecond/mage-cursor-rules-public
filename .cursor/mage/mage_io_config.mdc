---
description: 
globs: 
alwaysApply: true
---
**Version:** 0.1.1

## Default Profile

The `default` profile contains connection settings. Add credentials for the sources you use and remove or comment out the unused sections. Environment variables are commonly used for sensitive credentials.

```yaml
version: 0.1.1
default:
  # Default profile created for data IO access.
  # Add your credentials for the source you use, and delete the rest.

  # --- AWS ---
  AWS_ACCESS_KEY_ID: "{{ env_var('AWS_ACCESS_KEY_ID') }}"
  AWS_SECRET_ACCESS_KEY: "{{ env_var('AWS_SECRET_ACCESS_KEY') }}"
  AWS_SESSION_TOKEN: session_token # Used to generate Redshift credentials
  AWS_REGION: region

  # --- Algolia ---
  ALGOLIA_APP_ID: app_id
  ALGOLIA_API_KEY: api_key
  ALGOLIA_INDEX_NAME: index_name

  # --- Azure ---
  AZURE_CLIENT_ID: "{{ env_var('AZURE_CLIENT_ID') }}"
  AZURE_CLIENT_SECRET: "{{ env_var('AZURE_CLIENT_SECRET') }}"
  AZURE_STORAGE_ACCOUNT_NAME: "{{ env_var('AZURE_STORAGE_ACCOUNT_NAME') }}"
  AZURE_TENANT_ID: "{{ env_var('AZURE_TENANT_ID') }}"

  # --- Chroma ---
  CHROMA_COLLECTION: collection_name
  CHROMA_PATH: path

  # --- Clickhouse ---
  CLICKHOUSE_DATABASE: default
  CLICKHOUSE_HOST: host.docker.internal
  CLICKHOUSE_INTERFACE: http
  CLICKHOUSE_PASSWORD: null
  CLICKHOUSE_PORT: 8123
  CLICKHOUSE_USERNAME: null

  # --- Druid ---
  DRUID_HOST: hostname
  DRUID_PASSWORD: password
  DRUID_PATH: /druid/v2/sql/
  DRUID_PORT: 8082
  DRUID_SCHEME: http
  DRUID_USER: user

  # --- DuckDB ---
  DUCKDB_DATABASE: database
  DUCKDB_SCHEMA: main

  # --- Google Cloud Platform (GCP) ---
  # Use either service account key JSON content or a file path
  GOOGLE_SERVICE_ACC_KEY:
    type: service_account
    project_id: your-project-id
    private_key_id: your-key-id
    private_key: "-----BEGIN PRIVATE KEY-----\nyour_private_key\n-----END_PRIVATE_KEY"
    client_email: your-service-account@your-project.iam.gserviceaccount.com
    auth_uri: "https://accounts.google.com/o/oauth2/auth"
    token_uri: "https://accounts.google.com/o/oauth2/token"
    auth_provider_x509_cert_url: "https://www.googleapis.com/oauth2/v1/certs"
    client_x509_cert_url: "https://www.googleapis.com/robot/v1/metadata/x509/your-service-account@your-project.iam.gserviceaccount.com"
  GOOGLE_SERVICE_ACC_KEY_FILEPATH: "/path/to/your/service/account/key.json"
  GOOGLE_LOCATION: US # Optional: e.g., for BigQuery

  # --- MongoDB ---
  # Specify either the connection string or individual parameters
  MONGODB_CONNECTION_STRING: "mongodb://{username}:{password}@{host}:{port}/"
  MONGODB_HOST: host
  MONGODB_PORT: 27017
  MONGODB_USER: user
  MONGODB_PASSWORD: password
  MONGODB_DATABASE: database
  MONGODB_COLLECTION: collection

  # --- Microsoft SQL Server (MSSQL) ---
  MSSQL_DATABASE: database
  MSSQL_SCHEMA: schema
  MSSQL_DRIVER: "ODBC Driver 18 for SQL Server"
  MSSQL_HOST: host
  MSSQL_PASSWORD: password
  MSSQL_PORT: 1433
  MSSQL_USER: SA

  # --- MySQL ---
  MYSQL_DATABASE: database
  MYSQL_HOST: host
  MYSQL_PASSWORD: password
  MYSQL_PORT: 3306
  MYSQL_USER: root

  # --- Pinot ---
  PINOT_HOST: hostname
  PINOT_PASSWORD: password
  PINOT_PATH: /query/sql
  PINOT_PORT: 8000
  PINOT_SCHEME: http
  PINOT_USER: user

  # --- PostgreSQL ---
  POSTGRES_CONNECT_TIMEOUT: 10
  POSTGRES_DBNAME: postgres
  POSTGRES_SCHEMA: public # Optional
  POSTGRES_USER: username
  POSTGRES_PASSWORD: password
  POSTGRES_HOST: hostname
  POSTGRES_PORT: 5432

  # --- Qdrant ---
  QDRANT_COLLECTION: collection
  QDRANT_PATH: path

  # --- Redshift ---
  REDSHIFT_SCHEMA: public # Optional
  REDSHIFT_DBNAME: redshift_db_name
  REDSHIFT_HOST: your-cluster.your-region.redshift.amazonaws.com
  REDSHIFT_PORT: 5439
  # For temporary credentials (e.g., via AWS Session Token)
  REDSHIFT_TEMP_CRED_USER: temp_username
  REDSHIFT_TEMP_CRED_PASSWORD: temp_password
  # For standard DB user credentials
  REDSHIFT_DBUSER: redshift_db_user
  # Required if using IAM authentication or temp credentials
  REDSHIFT_CLUSTER_ID: your_cluster_id
  REDSHIFT_IAM_PROFILE: default

  # --- Snowflake ---
  SNOWFLAKE_USER: username
  SNOWFLAKE_PASSWORD: password
  SNOWFLAKE_ACCOUNT: your_account.your_region # e.g., xy12345.us-east-1
  SNOWFLAKE_DEFAULT_WH: null           # Optional default warehouse
  SNOWFLAKE_DEFAULT_DB: null           # Optional default database
  SNOWFLAKE_DEFAULT_SCHEMA: null       # Optional default schema
  # For key pair authentication
  SNOWFLAKE_PRIVATE_KEY_PASSPHRASE: null # Optional private key passphrase
  SNOWFLAKE_PRIVATE_KEY_PATH: null     # Optional private key path
  SNOWFLAKE_ROLE: null                 # Optional role name
  SNOWFLAKE_TIMEOUT: null              # Optional timeout in seconds

  # --- Trino ---
  trino:
    catalog: postgresql                # Change this to the catalog of your choice
    host: 127.0.0.1
    http_headers:
      X-Something: 'header=value'
    http_scheme: http
    password: your_password            # Optional
    port: 8080
    schema: core_data
    session_properties:                # Optional
      acc01.optimize_locality_enabled: false
      optimize_hash_generation: true
    source: trino-cli                  # Optional
    user: admin
    verify: /path/to/your/ca.crt       # Optional

  # --- Weaviate ---
  WEAVIATE_ENDPOINT: https://your-endpoint.weaviate.network # Your Weaviate instance URL
  WEAVIATE_INSTANCE_API_KEY: YOUR-WEAVIATE-API-KEY # API key for your Weaviate instance
  WEAVIATE_INFERENCE_API_KEY: YOUR-INFERENCE-API-KEY # e.g., OpenAI API key if using related modules
  WEAVIATE_COLLECTION: collection_name